{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#default_exp loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The loss function\n",
    "> We will define our loss function in this file. For general guidance we used the original pointpillars paper.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/qhs67/git/bachelorthesis_sven_thaele/code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class PointPillarsLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        logger.info(\"Initializing PointPillarsLoss module...\")\n",
    "        super(PointPillarsLoss, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, preds: list, writer: SummaryWriter = None, epoch: int = 0, i: int = 0) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the resulting, overall loss function. It consists of the occupancy loss for positive as well as\n",
    "        negative matches, and the regressional loss, which is intern calculated by positive match attributes.\n",
    "\n",
    "        :param preds: A list containing the matched tensors. The list has the following structure:\n",
    "                      [pred_occ(nb_matched_boxes),\n",
    "                       pred_cls(nb_matched_boxes),\n",
    "                       pred_head(nb_matched_boxes),\n",
    "                       pred_box(nb_matched_boxes, nb_attributes=7),\n",
    "                       gt_boxes(nb_matched_boxes, nb_attributes=7),\n",
    "                       neg_matches(nb_negative_match)]\n",
    "\n",
    "                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold\n",
    "                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold\n",
    "\n",
    "        :return: loss value as integer\n",
    "        \"\"\"\n",
    "        pred_occ, pred_cls, pred_head, pred_boxes, gt_boxes, neg_matches = preds\n",
    "\n",
    "        logger.info(\"Calculating loss...\")\n",
    "        logger.debug(f\"pred_occ: {pred_occ}{pred_occ.shape},\\n\"\n",
    "                     f\"pred_cls: {pred_cls}{pred_cls.shape},\\n\"\n",
    "                     f\"pred_head: {pred_head}{pred_head.shape},\\n\"\n",
    "                     f\"pred_boxes: {pred_boxes}{pred_boxes.shape},\\n\"\n",
    "                     f\"gt_boxes: {gt_boxes}{gt_boxes.shape},\\n\"\n",
    "                     f\"neg_matches: {neg_matches}{neg_matches.shape}\")\n",
    "\n",
    "\n",
    "        L_occ_pos = self.pos_occ_loss(preds)\n",
    "        L_occ_neg = self.neg_occ_loss(preds)\n",
    "        L_reg = self.reg_loss(preds, writer, epoch, i)\n",
    "        N_pos = pred_boxes.shape[0]\n",
    "        N_neg = neg_matches.shape[0]\n",
    "\n",
    "        # defined in VoxelNet paper\n",
    "        alpha = 1.5\n",
    "        beta = 1\n",
    "\n",
    "        if N_pos == 0 and N_neg == 0:\n",
    "            raise ValueError(\"Neither positive nor negative Matches.\")\n",
    "            #loss = 0.0\n",
    "\n",
    "        elif N_pos == 0:\n",
    "            loss = beta * 1/N_neg * L_occ_neg\n",
    "\n",
    "            if writer is not None:\n",
    "                writer.add_scalar(\"Epoch {}/L_occ_neg\".format(epoch), L_occ_neg/N_neg, i)\n",
    "                writer.add_scalar(\"Epoch {}/L_occ_pos\".format(epoch), 0, i)\n",
    "                writer.add_scalar(\"Epoch {}/L_reg\".format(epoch), 0, i)\n",
    "\n",
    "        elif N_neg == 0:\n",
    "            loss = alpha * 1/N_pos * L_occ_pos + L_reg\n",
    "\n",
    "            if writer is not None:\n",
    "                writer.add_scalar(\"Epoch {}/L_occ_neg\".format(epoch), 0, i)\n",
    "                writer.add_scalar(\"Epoch {}/L_occ_pos\".format(epoch), L_occ_pos/N_pos, i)\n",
    "                writer.add_scalar(\"Epoch {}/L_reg\".format(epoch), L_reg, i)\n",
    "\n",
    "        else:\n",
    "            loss = alpha * 1/N_pos * L_occ_pos + beta * 1/N_neg * L_occ_neg + L_reg\n",
    "\n",
    "            if writer is not None:\n",
    "                writer.add_scalar(\"Epoch {}/L_occ_neg\".format(epoch), L_occ_neg/N_neg, i)\n",
    "                writer.add_scalar(\"Epoch {}/L_occ_pos\".format(epoch), L_occ_pos/N_pos, i)\n",
    "                writer.add_scalar(\"Epoch {}/L_reg\".format(epoch), L_reg, i)\n",
    "\n",
    "\n",
    "        logger.debug(f\"Loss calculation complete.\\n\"\n",
    "                     f\"L_occ_pos: {L_occ_pos},\"\n",
    "                     f\"L_occ_neg: {L_occ_neg},\"\n",
    "                     f\"L_reg: {L_reg},\"\n",
    "                     f\"loss: {loss}\")\n",
    "\n",
    "        del preds, pred_occ, pred_cls, pred_head, pred_boxes, gt_boxes, neg_matches\n",
    "        del L_occ_pos, L_occ_neg, L_reg\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def reg_loss(self, preds: list, writer: SummaryWriter = None, epoch: int = 0, i: int = 0) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the regressional loss. The function is defined in the PointPillars paper. This here includes\n",
    "        localisation loss, class loss and directional loss.\n",
    "\n",
    "        :param preds: A list containing the matched tensors. The list has the following structure:\n",
    "                      [pred_occ(nb_matched_boxes),\n",
    "                       pred_cls(nb_matched_boxes),\n",
    "                       pred_head(nb_matched_boxes),\n",
    "                       pred_box(nb_matched_boxes, nb_attributes=7),\n",
    "                       gt_boxes(nb_matched_boxes, nb_attributes=7),\n",
    "                       neg_matches(nb_negative_match)]\n",
    "\n",
    "                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold\n",
    "                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold\n",
    "\n",
    "        :return: loss value as integer\n",
    "        \"\"\"\n",
    "        logger.debug(\"Calculating reg_loss...\")\n",
    "\n",
    "        _, _, _, pred_boxes, _, _ = preds\n",
    "        N_pos = pred_boxes.shape[0]\n",
    "\n",
    "        # no positive matches\n",
    "        if N_pos == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # definded by the PointPillars paper\n",
    "        beta_loc = 2\n",
    "        beta_cls = 1\n",
    "        beta_dir = 0.2\n",
    "\n",
    "        L_loc = self.loc_loss(preds)\n",
    "        L_cls = self.cls_loss(preds)\n",
    "        L_dir = self.dir_loss(preds)\n",
    "\n",
    "        L_reg = 1/N_pos * (beta_loc * L_loc + beta_cls * L_cls + beta_dir * L_dir)\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"Epoch {}/L_loc\".format(epoch), L_loc/N_pos, i)\n",
    "            writer.add_scalar(\"Epoch {}/L_cls\".format(epoch), L_cls/N_pos, i)\n",
    "            writer.add_scalar(\"Epoch {}/L_dir\".format(epoch), L_dir/N_pos, i)\n",
    "\n",
    "        logger.debug(f\"reg_loss calc complete.\\n\"\n",
    "                     f\"L_loc: {L_loc},\"\n",
    "                     f\"L_cls: {L_cls},\"\n",
    "                     f\"L_dir: {L_dir},\"\n",
    "                     f\"L_reg: {L_reg}\")\n",
    "\n",
    "        del L_loc, L_cls, L_dir, preds\n",
    "\n",
    "        return L_reg\n",
    "\n",
    "    def loc_loss(self, preds: list) -> float:\n",
    "        \"\"\"\n",
    "        The localisation loss is calculated. A set of individual equations is used, which later on are added together.\n",
    "        The exact equations can be obtained from the PointPillars paper.\n",
    "\n",
    "        :param preds: A list containing the matched tensors. The list has the following structure:\n",
    "                      [pred_occ(nb_matched_boxes),\n",
    "                       pred_cls(nb_matched_boxes),\n",
    "                       pred_head(nb_matched_boxes),\n",
    "                       pred_boxes(nb_matched_boxes, nb_attributes=7),\n",
    "                       gt_boxes(nb_matched_boxes, nb_attributes=7),\n",
    "                       neg_matches(nb_negative_match)]\n",
    "\n",
    "                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold\n",
    "                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold\n",
    "\n",
    "        :return: loss value as integer\n",
    "        \"\"\"\n",
    "        _, _, _, pred_boxes, gt_boxes, _ = preds\n",
    "        xa, ya, za, ha, wa, la, thetaa = torch.split(pred_boxes, 1, dim=1)\n",
    "        xg, yg, zg, hg, wg, lg, thetag = torch.split(gt_boxes, 1, dim=1)\n",
    "\n",
    "        logger.debug(f\"xa, ya, za, wa, la, ha, thetaa: {xa}, {ya}, {za}, {wa}, {la}, {ha}, {thetaa}\\n\"\n",
    "                     f\"xg, yg, zg, wg, lg, hg, thetag: {xg}, {yg}, {zg}, {wg}, {lg}, {hg}, {thetag}\")\n",
    "\n",
    "        diagonal = torch.sqrt(la**2 + wa**2)\n",
    "        dx = (xg - xa) / diagonal\n",
    "        dy = (yg - ya) / diagonal\n",
    "        dz = (zg - za) / ha\n",
    "        dl = torch.log(lg / la)\n",
    "        dw = torch.log(wg / wa)\n",
    "        dh = torch.log(hg / ha)\n",
    "        dtheta = torch.sin(thetaa - thetag)\n",
    "\n",
    "        logger.debug(f\"diagonal, dx, dy, dz, dw, dl, dh, dtheta: {diagonal}, {dx}, {dy}, {dz}, {dw}, {dl}, {dh}, {dtheta}\")\n",
    "\n",
    "        calc_values = [dx, dy, dz, dl, dw, dh, dtheta]\n",
    "        smooth_losses = []\n",
    "\n",
    "        # SmoothL1Loss() every individual loss in location loss\n",
    "        for value in calc_values:\n",
    "\n",
    "            loss_func = torch.nn.SmoothL1Loss(reduction='sum')\n",
    "            smooth_losses.append(loss_func(value, torch.zeros_like(value)))\n",
    "\n",
    "        return sum(smooth_losses)\n",
    "\n",
    "    def cls_loss(self, preds: list) -> float:\n",
    "        \"\"\"\n",
    "        Class loss is calculated. We use focal loss.\n",
    "\n",
    "        :param preds: A list containing the matched tensors. The list has the following structure:\n",
    "                      [pred_occ(nb_matched_boxes),\n",
    "                       pred_cls(nb_matched_boxes),\n",
    "                       pred_head(nb_matched_boxes),\n",
    "                       pred_boxes(nb_matched_boxes, nb_attributes=7),\n",
    "                       gt_boxes(nb_matched_boxes, nb_attributes=7),\n",
    "                       neg_matches(nb_negative_match)]\n",
    "\n",
    "                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold\n",
    "                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold\n",
    "\n",
    "        :return: loss value as integer\n",
    "        \"\"\"\n",
    "        _, pred_cls, _, _, _, _ = preds\n",
    "\n",
    "        target = torch.zeros_like(pred_cls, device=\"cuda:0\")\n",
    "        focal_loss = WeightedFocalLoss()\n",
    "\n",
    "        return focal_loss(pred_cls, target)\n",
    "\n",
    "    def dir_loss(self, preds: list) -> float:\n",
    "        \"\"\"\n",
    "        Directional loss is calculated.\n",
    "\n",
    "        :param preds: A list containing the matched tensors. The list has the following structure:\n",
    "                      [pred_occ(nb_matched_boxes),\n",
    "                       pred_cls(nb_matched_boxes),\n",
    "                       pred_head(nb_matched_boxes),\n",
    "                       pred_box(nb_matched_boxes, nb_attributes=7),\n",
    "                       gt_boxes(nb_matched_boxes, nb_attributes=7),\n",
    "                       neg_matches(nb_negative_match)]\n",
    "\n",
    "                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold\n",
    "                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold\n",
    "\n",
    "        :return: loss value as float\n",
    "        \"\"\"\n",
    "        # kitti convention: ry == 0 if object is aligned with x-axis and pointing right\n",
    "        _, _, pred_head, _, gt_boxes, _ = preds\n",
    "\n",
    "        # if the yaw rotation around the z-axis of the ground truth is higher than zero,\n",
    "        # the result is positive; otherwise, it is negative\n",
    "        # theta_gt      target\n",
    "        #   < 0           0\n",
    "        #   >= 0           +1\n",
    "\n",
    "        gt_theta = gt_boxes[:,6]\n",
    "        theta_greater_zero = gt_theta >= 0\n",
    "        target_greater_zero = theta_greater_zero.float()\n",
    "        target = torch.zeros_like(pred_head, device='cuda:0') + target_greater_zero\n",
    "\n",
    "        ce_loss = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "        return ce_loss(pred_head, target)\n",
    "\n",
    "    def pos_occ_loss(self, preds: list) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the binary entropy loss for positive matches. Therefore pred_occ tensor is used.\n",
    "\n",
    "        :param preds: A list containing the matched tensors. The list has the following structure:\n",
    "                      [pred_occ(nb_matched_boxes),\n",
    "                       pred_cls(nb_matched_boxes),\n",
    "                       pred_head(nb_matched_boxes),\n",
    "                       pred_box(nb_matched_boxes, nb_attributes=7),\n",
    "                       gt_boxes(nb_matched_boxes, nb_attributes=7),\n",
    "                       neg_matches(nb_negative_match)]\n",
    "\n",
    "                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold\n",
    "                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold\n",
    "\n",
    "        :return: loss value as integer\n",
    "        \"\"\"\n",
    "        pred_occ, _, _, _, _, _ = preds\n",
    "\n",
    "        if pred_occ.shape[0] == 0:\n",
    "            return 0.0\n",
    "\n",
    "        target = torch.ones_like(pred_occ, device='cuda:0')\n",
    "\n",
    "        #(binary) cross entropy loss\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "        return bce_loss(pred_occ, target)\n",
    "\n",
    "    def neg_occ_loss(self, preds: list) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the binary cross entropy loss for negative matches. Therefore neg_matches tensor is used.\n",
    "\n",
    "        :param preds: A list containing the matched tensors. The list has the following structure:\n",
    "                      [pred_occ(nb_matched_boxes),\n",
    "                       pred_cls(nb_matched_boxes),\n",
    "                       pred_head(nb_matched_boxes),\n",
    "                       pred_box(nb_matched_boxes, nb_attributes=7),\n",
    "                       gt_boxes(nb_matched_boxes, nb_attributes=7),\n",
    "                       neg_matches(nb_negative_match)]\n",
    "\n",
    "                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold\n",
    "                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold\n",
    "\n",
    "        :return: loss value as integer\n",
    "        \"\"\"\n",
    "        _, _, _, _, _, neg_matches = preds\n",
    "\n",
    "        if neg_matches.shape[0] == 0:\n",
    "            return 0.0\n",
    "\n",
    "        target = torch.zeros_like(neg_matches, device='cuda:0')\n",
    "\n",
    "        #(binary) cross entropy loss\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "        return bce_loss(neg_matches, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class WeightedFocalLoss(nn.Module):\n",
    "    \"Non weighted version of Focal Loss\"\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super(WeightedFocalLoss, self).__init__()\n",
    "        self.alpha = torch.cuda.FloatTensor([alpha, 1-alpha])\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "        \"\"\"Returns the focal loss for inputs\"\"\"\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        targets = targets.type(torch.long)\n",
    "        at = self.alpha.gather(0, targets.data.view(-1))\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = at*(1-pt)**self.gamma * BCE_loss\n",
    "        return F_loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.6516, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(100).cuda() * 2 - 1\n",
    "target = torch.zeros_like(a).cuda()\n",
    "\n",
    "focal_loss = WeightedFocalLoss()\n",
    "focal_loss(a, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([462])\n",
      "torch.Size([462])\n",
      "torch.Size([462])\n",
      "torch.Size([462, 7])\n",
      "torch.Size([462, 7])\n",
      "torch.Size([462])\n"
     ]
    }
   ],
   "source": [
    "input = [\n",
    "    torch.rand((1000)).cuda(),\n",
    "    torch.rand((1000)).cuda(),\n",
    "    torch.rand((1000)).cuda(),\n",
    "    torch.rand((1000, 7)).cuda(),\n",
    "    torch.rand((1000, 7)).cuda(),\n",
    "    torch.rand((1000)).cuda(),\n",
    "    (torch.rand((1000)).cuda() >=0.5).type(torch.IntTensor),\n",
    "]\n",
    "ppLoss = PointPillarsLoss()\n",
    "\n",
    "out = ppLoss._exlude_masked(input)\n",
    "for tens in out:\n",
    "    print(tens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4986, 0.0163, 0.1210, 0.7441, 0.5782, 0.6981, 0.7556],\n",
      "        [0.4181, 0.4219, 0.4841, 0.3865, 0.1049, 0.4564, 0.0951],\n",
      "        [0.3956, 0.9177, 0.3972, 0.6727, 0.4713, 0.6087, 0.1112],\n",
      "        [0.4597, 0.6505, 0.8173, 0.2113, 0.7539, 0.2706, 0.9028],\n",
      "        [0.0316, 0.6660, 0.7183, 0.6688, 0.3348, 0.2928, 0.3328],\n",
      "        [0.9797, 0.5109, 0.4738, 0.3201, 0.3925, 0.3667, 0.9568],\n",
      "        [0.9949, 0.8854, 0.2696, 0.3935, 0.9701, 0.8669, 0.7429],\n",
      "        [0.8059, 0.3103, 0.3384, 0.9785, 0.5852, 0.9211, 0.6828],\n",
      "        [0.8642, 0.1476, 0.8894, 0.5632, 0.3926, 0.8802, 0.2078],\n",
      "        [0.3242, 0.7258, 1.0000, 0.6910, 0.5313, 0.8182, 0.7950]]) torch.Size([10, 7])\n",
      "tensor([[0.4986],\n",
      "        [0.4181],\n",
      "        [0.3956],\n",
      "        [0.4597],\n",
      "        [0.0316],\n",
      "        [0.9797],\n",
      "        [0.9949],\n",
      "        [0.8059],\n",
      "        [0.8642],\n",
      "        [0.3242]]) tensor([[0.0163],\n",
      "        [0.4219],\n",
      "        [0.9177],\n",
      "        [0.6505],\n",
      "        [0.6660],\n",
      "        [0.5109],\n",
      "        [0.8854],\n",
      "        [0.3103],\n",
      "        [0.1476],\n",
      "        [0.7258]]) tensor([[0.1210],\n",
      "        [0.4841],\n",
      "        [0.3972],\n",
      "        [0.8173],\n",
      "        [0.7183],\n",
      "        [0.4738],\n",
      "        [0.2696],\n",
      "        [0.3384],\n",
      "        [0.8894],\n",
      "        [1.0000]]) tensor([[0.7441],\n",
      "        [0.3865],\n",
      "        [0.6727],\n",
      "        [0.2113],\n",
      "        [0.6688],\n",
      "        [0.3201],\n",
      "        [0.3935],\n",
      "        [0.9785],\n",
      "        [0.5632],\n",
      "        [0.6910]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(10, 7)\n",
    "print(a, a.shape)\n",
    "\n",
    "a1, a2, a3, a4, a5, a6, a7 = torch.split(a, 1, dim=1)\n",
    "print(a1, a2, a3, a4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 3 required positional arguments: 'writer', 'epoch', and 'i'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-41d22be2bda7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mppLoss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPointPillarsLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mppLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ba/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: forward() missing 3 required positional arguments: 'writer', 'epoch', and 'i'"
     ]
    }
   ],
   "source": [
    "input = [\n",
    "    torch.rand((1000)).cuda(),\n",
    "    torch.rand((1000)).cuda(),\n",
    "    torch.rand((1000)).cuda(),\n",
    "    torch.rand((1000, 7)).cuda(),\n",
    "    torch.rand((1000, 7)).cuda(),\n",
    "    torch.rand((500)).cuda()\n",
    "]\n",
    "\n",
    "ppLoss = PointPillarsLoss()\n",
    "loss = ppLoss(input)\n",
    "\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba",
   "language": "python",
   "name": "ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}