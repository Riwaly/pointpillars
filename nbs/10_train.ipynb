{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#default_exp train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/qhs67/git/bachelorthesis_sven_thaele/code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import logging\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "\n",
    "from pointpillars.utils.io import read_config, save_network_checkpoint, save_network\n",
    "from pointpillars.data.dataset import VelTrainDataset, collate_fn, OverfitSampler\n",
    "from pointpillars.modules.pointpillars import PointPillars, init_weights\n",
    "from pointpillars.loss import PointPillarsLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# time to identify the run on folders and checkpoints etc\n",
    "ident_time = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "log_formatter = logging.Formatter(log_format)\n",
    "\n",
    "log_handler = logging.FileHandler(\"/home/qhs67/git/bachelorthesis_sven_thaele/code/pointpillars.log\", mode='w')\n",
    "log_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(log_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# tensorboard writer\n",
    "run_folder = \"/home/qhs67/git/bachelorthesis_sven_thaele/code/runs/{}/\".format(ident_time)\n",
    "\n",
    "writer = SummaryWriter(run_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensor([[0.4479, 0.6738, 0.7426, 0.3690, 0.6762, 0.7121, 0.0316, 0.1435, 0.6628,\\n         0.7707],\\n        [0.7733, 0.5175, 0.4289, 0.0644, 0.7136, 0.4066, 0.0236, 0.3815, 0.0774,\\n         0.3601],\\n        [0.2550, 0.4316, 0.0791, 0.1322, 0.6743, 0.6415, 0.4585, 0.1059, 0.0959,\\n         0.1547],\\n        [0.8992, 0.5098, 0.9447, 0.5250, 0.8934, 0.7204, 0.5493, 0.9082, 0.6937,\\n         0.3766],\\n        [0.7474, 0.9609, 0.7570, 0.6120, 0.3702, 0.1869, 0.2984, 0.2591, 0.7336,\\n         0.2029],\\n        [0.7082, 0.6808, 0.8025, 0.9992, 0.7846, 0.9560, 0.4358, 0.2757, 0.0104,\\n         0.4979],\\n        [0.3730, 0.1065, 0.4406, 0.1950, 0.0024, 0.4755, 0.5494, 0.6395, 0.7281,\\n         0.9876],\\n        [0.5658, 0.1350, 0.2913, 0.0264, 0.8711, 0.2766, 0.2909, 0.9710, 0.9580,\\n         0.2983],\\n        [0.0583, 0.7612, 0.7287, 0.1307, 0.4188, 0.3796, 0.3439, 0.0260, 0.6932,\\n         0.2852],\\n        [0.8570, 0.3224, 0.0574, 0.7412, 0.3175, 0.3010, 0.2462, 0.2142, 0.3928,\\n         0.5228]])'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = torch.rand((10,10))\n",
    "tens.__str__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def _train_setup():\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    batch_size = 3\n",
    "    init_lr = 2 * 10**-4\n",
    "    #init_lr = 1 * 10**-4\n",
    "\n",
    "    logger.info(\"Start network training..\")\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.multiprocessing.set_start_method('spawn')\n",
    "\n",
    "    # TODO: move to config file\n",
    "    conf = read_config()\n",
    "    vel_folder = \"/home/qhs67/git/bachelorthesis_sven_thaele/code/data/kitti/training/velodyne/training\"\n",
    "    label_folder =\"/home/qhs67/git/bachelorthesis_sven_thaele/code/data/kitti/training/label_2/training\"\n",
    "\n",
    "    ds_train = VelTrainDataset(vel_folder, label_folder)\n",
    "    \"\"\"dl_train = torch.utils.data.DataLoader(ds_train,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=1,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=True)\"\"\"\n",
    "\n",
    "    sampler = OverfitSampler(ds_train, batch_size, nb_samples=20, shuffle=True)\n",
    "    for i in sampler:\n",
    "        print(i)\n",
    "\n",
    "    dl_train = torch.utils.data.DataLoader(ds_train,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler=sampler,\n",
    "                                           num_workers=0,\n",
    "                                           collate_fn=collate_fn)\n",
    "    \n",
    "    # modules\n",
    "    pointpillars = PointPillars(conf)\n",
    "    loss_func = PointPillarsLoss()\n",
    "    pointpillars.train()\n",
    "    loss_func.train()\n",
    "\n",
    "    # TODO: also init bias?\n",
    "    #pointpillars.apply(init_weights)\n",
    "    # move to gpu\n",
    "    pointpillars.cuda()\n",
    "    loss_func.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(pointpillars.parameters(), lr=init_lr)\n",
    "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 15, gamma=0.8, last_epoch=-1)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2000, gamma=0.8, last_epoch=-1)\n",
    "\n",
    "    return pointpillars, loss_func, optimizer, scheduler, dl_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def _train_step(batch: torch.Tensor,\n",
    "               pointpillars: torch.nn.Module,\n",
    "               loss_func: torch.nn.Module,\n",
    "               optimizer: torch.optim.Adam,\n",
    "               epoch: int,\n",
    "               i: int) -> torch.nn.Module:\n",
    "\n",
    "    \"\"\"\n",
    "    Performs a training step\n",
    "    \"\"\"\n",
    "\n",
    "    pil_batch, ind_batch, label_batch, label_mask = batch\n",
    "\n",
    "    # -> forward pass through network\n",
    "    preds = pointpillars(pil_batch, ind_batch, label_batch, label_mask)\n",
    "\n",
    "    loss = loss_func(preds, writer, epoch, i)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    del pil_batch, ind_batch, label_batch, preds\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def validate(network: torch.nn.Module, loss_func: torch.nn.Module, epoch, nbr_val_batches: int = 300):\n",
    "    \"\"\"\n",
    "    Validates the network on the loss function on the validation dataset\n",
    "    \"\"\"\n",
    "    batch_size = 3\n",
    "\n",
    "    validation_folder = \"/home/qhs67/git/bachelorthesis_sven_thaele/code/data/kitti/training/velodyne/validation\"\n",
    "    label_folder =\"/home/qhs67/git/bachelorthesis_sven_thaele/code/data/kitti/training/label_2/validation\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ds_val = VelTrainDataset(validation_folder, label_folder)\n",
    "        dl_val = torch.utils.data.DataLoader(ds_val,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=2,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=True)\n",
    "\n",
    "        running_val_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(dl_val):\n",
    "            # stop after given number of data\n",
    "            if i >= nbr_val_batches:\n",
    "                break\n",
    "\n",
    "            pil_batch, ind_batch, label_batch, label_mask = batch\n",
    "            preds = network(pil_batch, ind_batch, label_batch, label_mask)\n",
    "            loss = loss_func(preds)\n",
    "\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            print(\"Val Epoch: {}, Batch {} with Loss {} and running Loss {}.\".format(epoch, i, loss.item(), running_val_loss/(i+1)))\n",
    "\n",
    "            #writer.add_scalar(\"Epoch {}/Validation Loss\".format(epoch), running_val_loss/(i+1), i)\n",
    "            #writer.flush()\n",
    "\n",
    "        writer.add_scalar(\"Epochs/Validation Loss\", running_val_loss/nbr_val_batches, epoch)\n",
    "        writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def train(val: bool = False, save_nw: bool = False):\n",
    "    \"\"\"\n",
    "\n",
    "    :param val: bool if validation should be used\n",
    "    :param save_nw: bool if network state should be saved after training\n",
    "    \"\"\"\n",
    "    n_epochs = 10000\n",
    "\n",
    "\n",
    "    pointpillars, loss_func, optimizer, scheduler, dl_train = _train_setup()\n",
    "\n",
    "    try:\n",
    "        for epoch in range(n_epochs):\n",
    "            running_loss = 0\n",
    "            for i, batch in enumerate(dl_train):\n",
    "\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss = _train_step(batch, pointpillars, loss_func, optimizer, epoch, i)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                logger.debug(\"Epoch: {}, Batch {} with Loss {} and running Loss {}.\".format(epoch, i, loss.item(), running_loss/(i+1)))\n",
    "                print(\"Epoch: {}, Batch {} with Loss {} and running Loss {}.\".format(epoch, i, loss.item(), running_loss/(i+1)))\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                writer.add_scalar(\"Epoch {}/Running Loss\".format(epoch), running_loss/(i+1), i)\n",
    "                writer.flush()\n",
    "\n",
    "            # after epoch\n",
    "            scheduler.step()\n",
    "            writer.add_scalar(\"Epochs/Running Loss\", running_loss/len(dl_train), epoch)\n",
    "            writer.add_scalar(\"Epochs/Learning Rate\", scheduler.get_last_lr()[0], epoch)\n",
    "            writer.flush()\n",
    "\n",
    "            if val:\n",
    "                validate(pointpillars, loss_func, epoch, nbr_val_batches=10)\n",
    "\n",
    "        # after training\n",
    "        print('Finished Training')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        logger.exception(\"An exception occured\")\n",
    "        save_network_checkpoint(pointpillars, optimizer, scheduler, loss, ident_time, epoch)\n",
    "        exit()\n",
    "\n",
    "    if save_nw:\n",
    "        # save network to location from config\n",
    "        save_network(pointpillars, ident_time, n_epochs)\n",
    "\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "509\n",
      "1330\n",
      "1789\n",
      "519\n",
      "3472\n",
      "2845\n",
      "593\n",
      "3030\n",
      "3394\n",
      "1104\n",
      "2868\n",
      "1210\n",
      "2179\n",
      "1772\n",
      "1749\n",
      "694\n",
      "307\n",
      "2068\n",
      "697\n",
      "1877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qhs67/anaconda3/envs/ba/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of tensors must match except in dimension 1. Got 8 and 1 (The offending index is 0)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loss' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-a2883f890aa6>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(val, save_nw)\u001B[0m\n\u001B[1;32m     15\u001B[0m             \u001B[0mrunning_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdl_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ba/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    516\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 517\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    518\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ba/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    556\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 557\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    558\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ba/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollate_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/git/bachelorthesis_sven_thaele/code/pointpillars/data/dataset.py\u001B[0m in \u001B[0;36mcollate_fn\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m     \u001B[0mlabel_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconv_cam_to_vel_coord\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabel_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/git/bachelorthesis_sven_thaele/code/pointpillars/data/dataset.py\u001B[0m in \u001B[0;36mconv_cam_to_vel_coord\u001B[0;34m(label_batch)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 168\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0myv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mzv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbox_dims\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Got 8 and 1 (The offending index is 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-97a039155975>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmemory_allocated\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmemory_cached\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave_nw\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-11-a2883f890aa6>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(val, save_nw)\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"An exception occured\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 45\u001B[0;31m         \u001B[0msave_network_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpointpillars\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscheduler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mident_time\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     46\u001B[0m         \u001B[0mexit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m: local variable 'loss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_cached())\n",
    "train(val=False, save_nw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "if __name__ == '__main__':\n",
    "    train(val=False, save_nw=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba",
   "language": "python",
   "name": "ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}