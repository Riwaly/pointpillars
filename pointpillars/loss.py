# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_loss.ipynb (unless otherwise specified).

__all__ = ['logger', 'PointPillarsLoss', 'WeightedFocalLoss']

# Cell
import logging
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter

logger = logging.getLogger(__name__)

# Cell
class PointPillarsLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        logger.info("Initializing PointPillarsLoss module...")
        super(PointPillarsLoss, self).__init__()


    def forward(self, preds: list, writer: SummaryWriter = None, epoch: int = 0, i: int = 0) -> float:
        """
        Calculates the resulting, overall loss function. It consists of the occupancy loss for positive as well as
        negative matches, and the regressional loss, which is intern calculated by positive match attributes.

        :param preds: A list containing the matched tensors. The list has the following structure:
                      [pred_occ(nb_matched_boxes),
                       pred_cls(nb_matched_boxes),
                       pred_head(nb_matched_boxes),
                       pred_box(nb_matched_boxes, nb_attributes=7),
                       gt_boxes(nb_matched_boxes, nb_attributes=7),
                       neg_matches(nb_negative_match)]

                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold
                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold

        :return: loss value as integer
        """
        pred_occ, pred_cls, pred_head, pred_boxes, gt_boxes, neg_matches = preds

        logger.info("Calculating loss...")
        logger.debug(f"pred_occ: {pred_occ}{pred_occ.shape},\n"
                     f"pred_cls: {pred_cls}{pred_cls.shape},\n"
                     f"pred_head: {pred_head}{pred_head.shape},\n"
                     f"pred_boxes: {pred_boxes}{pred_boxes.shape},\n"
                     f"gt_boxes: {gt_boxes}{gt_boxes.shape},\n"
                     f"neg_matches: {neg_matches}{neg_matches.shape}")


        L_occ_pos = self.pos_occ_loss(preds)
        L_occ_neg = self.neg_occ_loss(preds)
        L_reg = self.reg_loss(preds, writer, epoch, i)
        N_pos = pred_boxes.shape[0]
        N_neg = neg_matches.shape[0]

        # defined in VoxelNet paper
        alpha = 1.5
        beta = 1

        if N_pos == 0 and N_neg == 0:
            raise ValueError("Neither positive nor negative Matches.")
            #loss = 0.0

        elif N_pos == 0:
            loss = beta * 1/N_neg * L_occ_neg

            if writer is not None:
                writer.add_scalar("Epoch {}/L_occ_neg".format(epoch), L_occ_neg/N_neg, i)
                writer.add_scalar("Epoch {}/L_occ_pos".format(epoch), 0, i)
                writer.add_scalar("Epoch {}/L_reg".format(epoch), 0, i)

        elif N_neg == 0:
            loss = alpha * 1/N_pos * L_occ_pos + L_reg

            if writer is not None:
                writer.add_scalar("Epoch {}/L_occ_neg".format(epoch), 0, i)
                writer.add_scalar("Epoch {}/L_occ_pos".format(epoch), L_occ_pos/N_pos, i)
                writer.add_scalar("Epoch {}/L_reg".format(epoch), L_reg, i)

        else:
            loss = alpha * 1/N_pos * L_occ_pos + beta * 1/N_neg * L_occ_neg + L_reg

            if writer is not None:
                writer.add_scalar("Epoch {}/L_occ_neg".format(epoch), L_occ_neg/N_neg, i)
                writer.add_scalar("Epoch {}/L_occ_pos".format(epoch), L_occ_pos/N_pos, i)
                writer.add_scalar("Epoch {}/L_reg".format(epoch), L_reg, i)


        logger.debug(f"Loss calculation complete.\n"
                     f"L_occ_pos: {L_occ_pos},"
                     f"L_occ_neg: {L_occ_neg},"
                     f"L_reg: {L_reg},"
                     f"loss: {loss}")

        del preds, pred_occ, pred_cls, pred_head, pred_boxes, gt_boxes, neg_matches
        del L_occ_pos, L_occ_neg, L_reg

        return loss


    def reg_loss(self, preds: list, writer: SummaryWriter = None, epoch: int = 0, i: int = 0) -> float:
        """
        Calculates the regressional loss. The function is defined in the PointPillars paper. This here includes
        localisation loss, class loss and directional loss.

        :param preds: A list containing the matched tensors. The list has the following structure:
                      [pred_occ(nb_matched_boxes),
                       pred_cls(nb_matched_boxes),
                       pred_head(nb_matched_boxes),
                       pred_box(nb_matched_boxes, nb_attributes=7),
                       gt_boxes(nb_matched_boxes, nb_attributes=7),
                       neg_matches(nb_negative_match)]

                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold
                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold

        :return: loss value as integer
        """
        logger.debug("Calculating reg_loss...")

        _, _, _, pred_boxes, _, _ = preds
        N_pos = pred_boxes.shape[0]

        # no positive matches
        if N_pos == 0:
            return 0.0

        # definded by the PointPillars paper
        beta_loc = 2
        beta_cls = 1
        beta_dir = 0.2

        L_loc = self.loc_loss(preds)
        L_cls = self.cls_loss(preds)
        L_dir = self.dir_loss(preds)

        L_reg = 1/N_pos * (beta_loc * L_loc + beta_cls * L_cls + beta_dir * L_dir)

        if writer is not None:
            writer.add_scalar("Epoch {}/L_loc".format(epoch), L_loc/N_pos, i)
            writer.add_scalar("Epoch {}/L_cls".format(epoch), L_cls/N_pos, i)
            writer.add_scalar("Epoch {}/L_dir".format(epoch), L_dir/N_pos, i)

        logger.debug(f"reg_loss calc complete.\n"
                     f"L_loc: {L_loc},"
                     f"L_cls: {L_cls},"
                     f"L_dir: {L_dir},"
                     f"L_reg: {L_reg}")

        del L_loc, L_cls, L_dir, preds

        return L_reg

    def loc_loss(self, preds: list) -> float:
        """
        The localisation loss is calculated. A set of individual equations is used, which later on are added together.
        The exact equations can be obtained from the PointPillars paper.

        :param preds: A list containing the matched tensors. The list has the following structure:
                      [pred_occ(nb_matched_boxes),
                       pred_cls(nb_matched_boxes),
                       pred_head(nb_matched_boxes),
                       pred_boxes(nb_matched_boxes, nb_attributes=7),
                       gt_boxes(nb_matched_boxes, nb_attributes=7),
                       neg_matches(nb_negative_match)]

                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold
                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold

        :return: loss value as integer
        """
        _, _, _, pred_boxes, gt_boxes, _ = preds
        xa, ya, za, ha, wa, la, thetaa = torch.split(pred_boxes, 1, dim=1)
        xg, yg, zg, hg, wg, lg, thetag = torch.split(gt_boxes, 1, dim=1)

        logger.debug(f"xa, ya, za, wa, la, ha, thetaa: {xa}, {ya}, {za}, {wa}, {la}, {ha}, {thetaa}\n"
                     f"xg, yg, zg, wg, lg, hg, thetag: {xg}, {yg}, {zg}, {wg}, {lg}, {hg}, {thetag}")

        diagonal = torch.sqrt(la**2 + wa**2)
        dx = (xg - xa) / diagonal
        dy = (yg - ya) / diagonal
        dz = (zg - za) / ha
        dl = torch.log(lg / la)
        dw = torch.log(wg / wa)
        dh = torch.log(hg / ha)
        dtheta = torch.sin(thetaa - thetag)

        logger.debug(f"diagonal, dx, dy, dz, dw, dl, dh, dtheta: {diagonal}, {dx}, {dy}, {dz}, {dw}, {dl}, {dh}, {dtheta}")

        calc_values = [dx, dy, dz, dl, dw, dh, dtheta]
        smooth_losses = []

        # SmoothL1Loss() every individual loss in location loss
        for value in calc_values:

            loss_func = torch.nn.SmoothL1Loss(reduction='sum')
            smooth_losses.append(loss_func(value, torch.zeros_like(value)))

        return sum(smooth_losses)

    def cls_loss(self, preds: list) -> float:
        """
        Class loss is calculated. We use focal loss.

        :param preds: A list containing the matched tensors. The list has the following structure:
                      [pred_occ(nb_matched_boxes),
                       pred_cls(nb_matched_boxes),
                       pred_head(nb_matched_boxes),
                       pred_boxes(nb_matched_boxes, nb_attributes=7),
                       gt_boxes(nb_matched_boxes, nb_attributes=7),
                       neg_matches(nb_negative_match)]

                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold
                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold

        :return: loss value as integer
        """
        _, pred_cls, _, _, _, _ = preds

        target = torch.zeros_like(pred_cls, device="cuda:0")
        focal_loss = WeightedFocalLoss()

        return focal_loss(pred_cls, target)

    def dir_loss(self, preds: list) -> float:
        """
        Directional loss is calculated.

        :param preds: A list containing the matched tensors. The list has the following structure:
                      [pred_occ(nb_matched_boxes),
                       pred_cls(nb_matched_boxes),
                       pred_head(nb_matched_boxes),
                       pred_box(nb_matched_boxes, nb_attributes=7),
                       gt_boxes(nb_matched_boxes, nb_attributes=7),
                       neg_matches(nb_negative_match)]

                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold
                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold

        :return: loss value as float
        """
        # kitti convention: ry == 0 if object is aligned with x-axis and pointing right
        _, _, pred_head, _, gt_boxes, _ = preds

        # if the yaw rotation around the z-axis of the ground truth is higher than zero,
        # the result is positive; otherwise, it is negative
        # theta_gt      target
        #   < 0           0
        #   >= 0           +1

        gt_theta = gt_boxes[:,6]
        theta_greater_zero = gt_theta >= 0
        target_greater_zero = theta_greater_zero.float()
        target = torch.zeros_like(pred_head, device='cuda:0') + target_greater_zero

        ce_loss = nn.BCEWithLogitsLoss(reduction='sum')
        return ce_loss(pred_head, target)

    def pos_occ_loss(self, preds: list) -> float:
        """
        Calculates the binary entropy loss for positive matches. Therefore pred_occ tensor is used.

        :param preds: A list containing the matched tensors. The list has the following structure:
                      [pred_occ(nb_matched_boxes),
                       pred_cls(nb_matched_boxes),
                       pred_head(nb_matched_boxes),
                       pred_box(nb_matched_boxes, nb_attributes=7),
                       gt_boxes(nb_matched_boxes, nb_attributes=7),
                       neg_matches(nb_negative_match)]

                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold
                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold

        :return: loss value as integer
        """
        pred_occ, _, _, _, _, _ = preds

        if pred_occ.shape[0] == 0:
            return 0.0

        target = torch.ones_like(pred_occ, device='cuda:0')

        #(binary) cross entropy loss
        bce_loss = nn.BCEWithLogitsLoss(reduction='sum')
        return bce_loss(pred_occ, target)

    def neg_occ_loss(self, preds: list) -> float:
        """
        Calculates the binary cross entropy loss for negative matches. Therefore neg_matches tensor is used.

        :param preds: A list containing the matched tensors. The list has the following structure:
                      [pred_occ(nb_matched_boxes),
                       pred_cls(nb_matched_boxes),
                       pred_head(nb_matched_boxes),
                       pred_box(nb_matched_boxes, nb_attributes=7),
                       gt_boxes(nb_matched_boxes, nb_attributes=7),
                       neg_matches(nb_negative_match)]

                       gt_boxes are the gt_boxes matched to each pred_box with iou >= pos_iou_threshold
                       neg_match gives the pred_occ for every box with a iou match lower than the neg_iou_threshold

        :return: loss value as integer
        """
        _, _, _, _, _, neg_matches = preds

        if neg_matches.shape[0] == 0:
            return 0.0

        target = torch.zeros_like(neg_matches, device='cuda:0')

        #(binary) cross entropy loss
        bce_loss = nn.BCEWithLogitsLoss(reduction='sum')

        return bce_loss(neg_matches, target)


# Cell
class WeightedFocalLoss(nn.Module):
    "Non weighted version of Focal Loss"
    def __init__(self, alpha=0.25, gamma=2):
        super(WeightedFocalLoss, self).__init__()
        self.alpha = torch.cuda.FloatTensor([alpha, 1-alpha])
        self.gamma = gamma

    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> float:
        """Returns the focal loss for inputs"""
        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')
        targets = targets.type(torch.long)
        at = self.alpha.gather(0, targets.data.view(-1))
        pt = torch.exp(-BCE_loss)
        F_loss = at*(1-pt)**self.gamma * BCE_loss
        return F_loss.sum()